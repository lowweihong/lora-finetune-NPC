{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Get HF_TOKEN from environment variable\n",
    "hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\n",
    "        \"HF_TOKEN environment variable is not set. \"\n",
    "        \"Please set it using: export HF_TOKEN='your_token_here'\"\n",
    "    )\n",
    "\n",
    "# Login to HuggingFace\n",
    "login(token=hf_token)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b845356-35a8-4c5a-a6f0-bade8df70bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Get HF_TOKEN from environment variable\n",
    "hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\n",
    "        \"HF_TOKEN environment variable is not set. \"\n",
    "        \"Please set it using: export HF_TOKEN='your_token_here'\"\n",
    "    )\n",
    "\n",
    "# Login to HuggingFace\n",
    "login(token=hf_token)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "# Format for SFT: Add persona to system prompt\n",
    "def format_example(example):\n",
    "    system = f\"You are {example['Name']}, {example['Biography']}. Respond in character with emotion: {example['Emotion']}.\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": example[\"Query\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"Response\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"amaydle/npc-dialogue\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5cd9fa3-348e-4f2a-9ce4-20fb93d45952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Name', 'Biography', 'Query', 'Response', 'Emotion'],\n",
       "    num_rows: 1723\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"amaydle/npc-dialogue\", split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27a455d-3dfe-416f-8e98-6a090e48d0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 71)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataset.to_pandas()['Response'].apply(lambda x:len(x.split())).min(), train_dataset.to_pandas()['Response'].apply(lambda x:len(x.split())).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc4a6d4-044b-409b-9e3d-e218adeaf3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token = train_dataset.to_pandas()['Response'].apply(lambda x:len(x.split())).max()*2\n",
    "max_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88704182-6c78-4756-966d-9edfc8caa2e1",
   "metadata": {},
   "source": [
    "> Use 150 as max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a62081b-7ebf-4759-85eb-d4bbc40fa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dc87b49-f735-4aac-b77f-9e3735fc41d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Query</th>\n",
       "      <th>Response</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naina Mathur</td>\n",
       "      <td>Naina Mathur is a determined and passionate te...</td>\n",
       "      <td>What is the biggest challenge you face as a te...</td>\n",
       "      <td>Ensuring every student receives the individual...</td>\n",
       "      <td>Concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>Zephyr is a mischievous fairy who loves playin...</td>\n",
       "      <td>What motivates you to play pranks on people?</td>\n",
       "      <td>It's just who I am, I guess. I love seeing peo...</td>\n",
       "      <td>Playfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arn, the Knight Templar</td>\n",
       "      <td>Arn is a highly skilled and honorable knight,</td>\n",
       "      <td>Can you describe yourself in three words?</td>\n",
       "      <td>\"Courageous, dedicated, honorable.\"</td>\n",
       "      <td>Pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arinthal</td>\n",
       "      <td>Arinthal is an elven ranger from the ancient f...</td>\n",
       "      <td>Have you ever been to a city?</td>\n",
       "      <td>Cities are noisy and overwhelming.</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiger</td>\n",
       "      <td>Tiger is a highly skilled and fearless spy wor...</td>\n",
       "      <td>What is the most valuable thing in your life?</td>\n",
       "      <td>My country and the people I love.</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Marcella Ravenwood</td>\n",
       "      <td>Marcella Ravenwood is a powerful sorceress who...</td>\n",
       "      <td>Do you have any magical artifacts that you che...</td>\n",
       "      <td>Yes, I have a magical tome that has been passe...</td>\n",
       "      <td>Sentimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Lyra Dawnstrider</td>\n",
       "      <td>Lyra Dawnstrider is a high-elf ranger from the...</td>\n",
       "      <td>What is your ultimate goal in life?</td>\n",
       "      <td>To see the natural world flourish, long after ...</td>\n",
       "      <td>Peacefulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Sailor Moon</td>\n",
       "      <td>Sailor Moon is the protector of the galaxy, de...</td>\n",
       "      <td>What is the most challenging battle you've fou...</td>\n",
       "      <td>Against Queen Nehelenia, she was a tough oppon...</td>\n",
       "      <td>Triumphant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Arn, the Knight Templar</td>\n",
       "      <td>Arn is a highly skilled and honorable knight,</td>\n",
       "      <td>Have you ever made a difficult decision?</td>\n",
       "      <td>\"Difficult decisions, for the greater good.\"</td>\n",
       "      <td>Conviction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Light Yagami</td>\n",
       "      <td>Light Yagami is a highly intelligent high scho...</td>\n",
       "      <td>What do you think of the police?</td>\n",
       "      <td>They are a nuisance that must be dealt with.</td>\n",
       "      <td>Contemptuous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  \\\n",
       "0               Naina Mathur   \n",
       "1                     Zephyr   \n",
       "2    Arn, the Knight Templar   \n",
       "3                   Arinthal   \n",
       "4                      Tiger   \n",
       "..                       ...   \n",
       "187       Marcella Ravenwood   \n",
       "188         Lyra Dawnstrider   \n",
       "189              Sailor Moon   \n",
       "190  Arn, the Knight Templar   \n",
       "191             Light Yagami   \n",
       "\n",
       "                                             Biography  \\\n",
       "0    Naina Mathur is a determined and passionate te...   \n",
       "1    Zephyr is a mischievous fairy who loves playin...   \n",
       "2        Arn is a highly skilled and honorable knight,   \n",
       "3    Arinthal is an elven ranger from the ancient f...   \n",
       "4    Tiger is a highly skilled and fearless spy wor...   \n",
       "..                                                 ...   \n",
       "187  Marcella Ravenwood is a powerful sorceress who...   \n",
       "188  Lyra Dawnstrider is a high-elf ranger from the...   \n",
       "189  Sailor Moon is the protector of the galaxy, de...   \n",
       "190      Arn is a highly skilled and honorable knight,   \n",
       "191  Light Yagami is a highly intelligent high scho...   \n",
       "\n",
       "                                                 Query  \\\n",
       "0    What is the biggest challenge you face as a te...   \n",
       "1         What motivates you to play pranks on people?   \n",
       "2            Can you describe yourself in three words?   \n",
       "3                        Have you ever been to a city?   \n",
       "4        What is the most valuable thing in your life?   \n",
       "..                                                 ...   \n",
       "187  Do you have any magical artifacts that you che...   \n",
       "188                What is your ultimate goal in life?   \n",
       "189  What is the most challenging battle you've fou...   \n",
       "190           Have you ever made a difficult decision?   \n",
       "191                   What do you think of the police?   \n",
       "\n",
       "                                              Response       Emotion  \n",
       "0    Ensuring every student receives the individual...       Concern  \n",
       "1    It's just who I am, I guess. I love seeing peo...   Playfulness  \n",
       "2                  \"Courageous, dedicated, honorable.\"         Pride  \n",
       "3                   Cities are noisy and overwhelming.       Disgust  \n",
       "4                    My country and the people I love.          Love  \n",
       "..                                                 ...           ...  \n",
       "187  Yes, I have a magical tome that has been passe...   Sentimental  \n",
       "188  To see the natural world flourish, long after ...  Peacefulness  \n",
       "189  Against Queen Nehelenia, she was a tough oppon...    Triumphant  \n",
       "190       \"Difficult decisions, for the greater good.\"    Conviction  \n",
       "191       They are a nuisance that must be dealt with.  Contemptuous  \n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51dd416d-9fb0-45b9-829f-9e05c47dd688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install trl\n",
    "# pip install flash-attn --no-build-isolation\n",
    "# pip install transformers==4.57.1 #Original: 4.57.1\n",
    "# pip install transformers==4.45.2\n",
    "# pip install flash-attn==2.5.5\n",
    "# pip install absl-py rouge-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac17ae1-a545-4843-8fde-0e04255b6bf4",
   "metadata": {},
   "source": [
    "# Final eval\n",
    "\n",
    "trained on 10 epochs, eval on BERT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aed21d1-8d73-43b6-baee-e7f8f2afcbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Base Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160b5015b9a4444590eb14a9069fc70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Perplexity: 44.57640838623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model BLEU: 0.0000 | ROUGE-L: 0.0476 | BERTScore: 0.8389\n",
      "ROUGE-1: 0.0476 | ROUGE-2: 0.0000 | ROUGE-L: 0.0476\n",
      "Evaluating Fine-Tuned Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010bbfea27fe4f6987b84b0fae7f70ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model Perplexity: 61.886661529541016\n",
      "Fine-Tuned Model BLEU: 0.0000 | ROUGE-L: 0.2353 | BERTScore: 0.8730\n",
      "ROUGE-1: 0.2353 | ROUGE-2: 0.1333 | ROUGE-L: 0.2353\n",
      "\n",
      "============================================================\n",
      "Qualitative Comparison:\n",
      "============================================================\n",
      "\n",
      "Prompt: You are a grumpy blacksmith. Player: What about the dragon?\n",
      "Reference: That beast's fire could melt my forge! Stay away, fool!\n",
      "Base Generation:  Ah, the mythical dragon, a creature often depicted with scales and breathing fire. I suppose you are referring to the dragon mythos or the dragon as commonly described in various cultures?\n",
      "Fine-Tuned Generation:  Dragon's fire, strong as heat.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "# Download punkt tokenizer for sentence tokenization (needed for ROUGE)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Clear cache at start\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Quantization config (4-bit to fit on GPU)\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load tokenizer once (shared)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "# Function to load model with low memory\n",
    "def load_model(path, quant_config=None):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        path,\n",
    "        quantization_config=quant_config,\n",
    "        device_map=\"auto\",  # Auto-shard if needed\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    model.eval()  # Eval mode\n",
    "    return model\n",
    "\n",
    "# Test data (expand with your NPC examples)\n",
    "test_data = [\n",
    "    {\"prompt\": \"You are a grumpy blacksmith. Player: What about the dragon?\", \n",
    "     \"reference\": \"That beast's fire could melt my forge! Stay away, fool!\"},\n",
    "    # Add more: e.g., {\"prompt\": \"...\", \"reference\": \"...\"}\n",
    "]\n",
    "\n",
    "# Function to generate with chat template\n",
    "def generate_response(generator, prompt, reference):\n",
    "    # Structure as chat messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt.split(\"Player:\")[0].strip()},  # E.g., \"You are a grumpy blacksmith.\"\n",
    "        {\"role\": \"user\", \"content\": prompt.split(\"Player:\")[1].strip() if \"Player:\" in prompt else prompt}  # E.g., \"What about the dragon?\"\n",
    "    ]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return generator(formatted_prompt, return_full_text=False)[0][\"generated_text\"]  # Don't echo prompt\n",
    "\n",
    "# Note: Model evaluation is now done using the evaluate_model() function below\n",
    "\n",
    "# Compute perplexity (lower better)\n",
    "def compute_perplexity(model, tokenizer, texts, batch_size=4):\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            total_loss += outputs.loss.item() * len(batch)\n",
    "    return torch.exp(torch.tensor(total_loss / len(texts))).item()\n",
    "\n",
    "# Load metrics once (reusable)\n",
    "_bleu = evaluate.load(\"bleu\")\n",
    "_rouge = evaluate.load(\"rouge\")\n",
    "_bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "def compute_all_metrics(predictions, references):\n",
    "    \"\"\"Compute BLEU, ROUGE, and BERTScore metrics.\"\"\"\n",
    "    # Rouge expects a newline after each sentence\n",
    "    rouge_base_preds = [\"\\n\".join(nltk.sent_tokenize(pred.lower().strip())) for pred in predictions]\n",
    "    rouge_base_refs = [\"\\n\".join(nltk.sent_tokenize(ref.lower().strip())) for ref in references]\n",
    "    \n",
    "    # Compute metrics\n",
    "    bleu_score = _bleu.compute(predictions=predictions, references=references)[\"bleu\"]\n",
    "    # rouge_result = _rouge.compute(predictions=rouge_decoded_preds, references=rouge_decoded_labels, use_stemmer=True)\n",
    "    rouge_result = _rouge.compute(predictions=rouge_base_preds, references=rouge_base_refs, use_stemmer=True)\n",
    "    base_rouge = rouge_result[\"rougeL\"]\n",
    "    \n",
    "    bertscore_result = _bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "    \n",
    "    return {\n",
    "        \"bleu\": bleu_score,\n",
    "        \"rouge1\": rouge_result[\"rouge1\"],\n",
    "        \"rouge2\": rouge_result[\"rouge2\"],\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bertscore_f1\": bertscore_result[\"f1\"][0] if isinstance(bertscore_result[\"f1\"], list) else bertscore_result[\"f1\"]\n",
    "    }\n",
    "\n",
    "def evaluate_model(model_path, test_data, model_name, quant_config, tokenizer, max_new_tokens=150):\n",
    "    \"\"\"Evaluate a model: load, generate, compute metrics.\"\"\"\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    # Load model and generator\n",
    "    model = load_model(model_path, quant_config)\n",
    "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, \n",
    "                        max_new_tokens=max_new_tokens, device_map=\"auto\")\n",
    "    \n",
    "    # Generate responses\n",
    "    generations = [generate_response(generator, item[\"prompt\"], item[\"reference\"]) \n",
    "                   for item in test_data]\n",
    "    references = [item[\"reference\"] for item in test_data]\n",
    "    \n",
    "    # Compute perplexity\n",
    "    ppl = compute_perplexity(model, tokenizer, references)\n",
    "    print(f\"{model_name} Perplexity: {ppl}\")\n",
    "    \n",
    "    # Compute all metrics\n",
    "    metrics = compute_all_metrics(generations, references)\n",
    "    print(f\"{model_name} BLEU: {metrics['bleu']:.4f} | ROUGE-L: {metrics['rougeL']:.4f} | BERTScore: {metrics['bertscore_f1']:.4f}\")\n",
    "    print(f\"ROUGE-1: {metrics['rouge1']:.4f} | ROUGE-2: {metrics['rouge2']:.4f} | ROUGE-L: {metrics['rougeL']:.4f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    del generator\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return generations, metrics, ppl\n",
    "\n",
    "# Extract references once\n",
    "references = [item[\"reference\"] for item in test_data]\n",
    "\n",
    "# Evaluate base model\n",
    "base_generations, base_metrics, base_ppl = evaluate_model(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\", \n",
    "    test_data, \n",
    "    \"Base Model\",\n",
    "    quant_config, \n",
    "    tokenizer, \n",
    "    max_new_tokens=max_token\n",
    ")\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "fine_generations, fine_metrics, fine_ppl = evaluate_model(\n",
    "    \"./npc_finetuned_bertscore-eval-noeval\", \n",
    "    test_data, \n",
    "    \"Fine-Tuned Model\",\n",
    "    quant_config, \n",
    "    tokenizer, \n",
    "    max_new_tokens=max_token\n",
    ")\n",
    "\n",
    "# Compare generations qualitatively\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Qualitative Comparison:\")\n",
    "print(\"=\"*60)\n",
    "for i, item in enumerate(test_data):\n",
    "    print(f\"\\nPrompt: {item['prompt']}\")\n",
    "    print(f\"Reference: {item['reference']}\")\n",
    "    print(f\"Base Generation: {base_generations[i]}\")\n",
    "    print(f\"Fine-Tuned Generation: {fine_generations[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5f2d5d6-75e5-4930-934c-db9efe3261d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0195f2506b9b4e109054282578354f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Friendship, important, always.', ' Dragons, dangerous, rare.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_model = load_model(\"./npc_finetuned_bertscore-eval-noeval\", quant_config)\n",
    "\n",
    "test_data = [\n",
    "    {\"prompt\": \"You are a Bikram is a rough and tough smuggler from the streets of Calcutta, India. Player: What is your opinion on friendship??\", \n",
    "     \"reference\": \"Friendship is a bond stronger than blood.\"},\n",
    "    # Add more: e.g., {\"prompt\": \"...\", \"reference\": \"...\"}\n",
    "    {\"prompt\": \"You are a grumpy blacksmith. Player: What about the dragon?\", \n",
    "     \"reference\": \"That beast's fire could melt my forge! Stay away, fool!\"},\n",
    "]\n",
    "\n",
    "fine_generator = pipeline(\"text-generation\", model=fine_model, tokenizer=tokenizer, max_new_tokens=max_token, device_map=\"auto\")\n",
    "\n",
    "\n",
    "[generate_response(fine_generator, \n",
    "                   item[\"prompt\"], \n",
    "                   item[\"reference\"]) for item in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c722acf-c9b1-42fd-8a35-c7a78dd28707",
   "metadata": {},
   "source": [
    "## Generate all evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b0690d3-8b71-48bb-ab23-195c3b49458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import evaluate\n",
    "\n",
    "def format_eval_example(example):\n",
    "    system = f\"You are {example['Name']}, {example['Biography']}. Respond in character with emotion: {example['Emotion']}.\"\n",
    "    return {\n",
    "        'prompt': f\"{system}. Player: {example['Query']}\",\n",
    "        'reference': example['Response']\n",
    "    }\n",
    "\n",
    "# Load tokenizer once (shared)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "# Function to load model with low memory\n",
    "def load_model(path, quant_config=None):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        path,\n",
    "        quantization_config=quant_config,\n",
    "        device_map=\"auto\",  # Auto-shard if needed\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    model.eval()  # Eval mode\n",
    "    return model\n",
    "# Function to generate with chat template\n",
    "def generate_response(generator, prompt, reference):\n",
    "    # Structure as chat messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt.split(\"Player:\")[0].strip()},  # E.g., \"You are a grumpy blacksmith.\"\n",
    "        {\"role\": \"user\", \"content\": prompt.split(\"Player:\")[1].strip() if \"Player:\" in prompt else prompt}  # E.g., \"What about the dragon?\"\n",
    "    ]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return generator(formatted_prompt, return_full_text=False)[0][\"generated_text\"]  # Don't echo prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c0339cf-703c-496c-9fe5-edec0cf56b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a02c8430204c19a0d8f14721ee0feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9a4dc73f7448948e81ea9c5ed343a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Clear cache at start\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Quantization config (4-bit to fit on GPU)\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "fine_model = load_model(\"./npc_finetuned_bertscore-eval-noeval\", quant_config)\n",
    "fine_generator = pipeline(\"text-generation\", model=fine_model, tokenizer=tokenizer, max_new_tokens=max_token, device_map=\"auto\")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "base_model = load_model(\"microsoft/Phi-3-mini-4k-instruct\", quant_config)  # Assuming this is your model load function\n",
    "base_model.to(device)  # Ensure on device\n",
    "base_generator = pipeline(\"text-generation\", model=base_model, tokenizer=tokenizer, max_new_tokens=max_token, device_map=\"auto\")\n",
    "\n",
    "\n",
    "# gen_replies = []\n",
    "# for idx, row in df.iterrows():\n",
    "#     item = format_eval_example(row)\n",
    "#     res = generate_response(fine_generator, item[\"prompt\"], item[\"reference\"]).strip()\n",
    "#     gen_replies.append(res)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cb2806d-b1a3-4e74-a5bf-2d197b6bcf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8049d5b-b3c6-4ab7-86b6-a2b2231948c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [10:03<00:00, 100.54s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define collate for batching\n",
    "def collate_fn(batch):\n",
    "    prompts = [format_eval_example(row)[\"prompt\"] for row in batch]  # Extract prompts\n",
    "    references = [format_eval_example(row)[\"reference\"] for row in batch]  # Extract references if needed\n",
    "    return prompts, references\n",
    "\n",
    "dataloader = DataLoader(df.to_dict('records'), batch_size=32, collate_fn=collate_fn)  # Batch size adjust based on VRAM\n",
    "\n",
    "based_gen_replies = []\n",
    "gen_replies = []\n",
    "for batch_prompts, batch_refs in tqdm(dataloader):\n",
    "    # Tokenize batched prompts\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    # Generate in batch\n",
    "    with torch.no_grad():\n",
    "        outputs = base_model.generate(**inputs, max_new_tokens=max_token, do_sample=False)  # Adjust sampling if needed\n",
    "        outputs_ft = fine_model.generate(**inputs, max_new_tokens=max_token, do_sample=False)  # Adjust sampling if needed\n",
    "    \n",
    "    # Decode\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    decoded_ft = tokenizer.batch_decode(outputs_ft, skip_special_tokens=True)\n",
    "    \n",
    "    # Process each (strip, etc.)\n",
    "    res_batch = [generate_response(base_generator, prompt, ref).strip() for prompt, ref, dec in zip(batch_prompts, batch_refs, decoded)]\n",
    "    res_batch = [x.strip('\"') for x in res_batch]\n",
    "    \n",
    "    res_batch_ft = [generate_response(fine_generator, prompt, ref).strip() for prompt, ref, dec in zip(batch_prompts, batch_refs, decoded_ft)]\n",
    "    res_batch_ft = [x.strip('\"') for x in res_batch_ft]\n",
    "    \n",
    "    based_gen_replies.extend(res_batch)\n",
    "    gen_replies.extend(res_batch_ft)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "249012ac-3614-410b-9e21-f81c32002c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gen_replies'] = gen_replies\n",
    "df['based_replies'] = based_gen_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ea5c0c7-77c5-40d2-a57c-89a13c006f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>gen_replies</th>\n",
       "      <th>based_replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensuring every student receives the individual...</td>\n",
       "      <td>Lack of resources and support.</td>\n",
       "      <td>The biggest challenge I face as a teacher is b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's just who I am, I guess. I love seeing peo...</td>\n",
       "      <td>I find it amusing to watch people's reactions ...</td>\n",
       "      <td>Ah, my dear friend, your curiosity warms my he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Courageous, dedicated, honorable.\"</td>\n",
       "      <td>Honorable, fearless, dedicated.</td>\n",
       "      <td>As a Knight Templar, I can be described as val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cities are noisy and overwhelming.</td>\n",
       "      <td>Cities are no place for a ranger.</td>\n",
       "      <td>No, I have never been to a city. As a creature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My country and the people I love.</td>\n",
       "      <td>My family, they are my motivation.</td>\n",
       "      <td>As Tiger, my work and my team are the most val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Yes, I have a magical tome that has been passe...</td>\n",
       "      <td>I have a magical amulet that has been passed d...</td>\n",
       "      <td>Ah, the question of magic and its cherished tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>To see the natural world flourish, long after ...</td>\n",
       "      <td>That is difficult to answer. I live in the mom...</td>\n",
       "      <td>Ah, my dear adventurers, I often ponder the gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Against Queen Nehelenia, she was a tough oppon...</td>\n",
       "      <td>The battle against Queen Beryl, the sorceress,...</td>\n",
       "      <td>As a Sailor Scout, I've faced countless battle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>\"Difficult decisions, for the greater good.\"</td>\n",
       "      <td>Difficult, but necessary.</td>\n",
       "      <td>Indeed, as a Knight Templar, I have faced many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>They are a nuisance that must be dealt with.</td>\n",
       "      <td>They're just obstacles in my path.</td>\n",
       "      <td>Well, they do try, don't they? Always chasing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Response  \\\n",
       "0    Ensuring every student receives the individual...   \n",
       "1    It's just who I am, I guess. I love seeing peo...   \n",
       "2                  \"Courageous, dedicated, honorable.\"   \n",
       "3                   Cities are noisy and overwhelming.   \n",
       "4                    My country and the people I love.   \n",
       "..                                                 ...   \n",
       "187  Yes, I have a magical tome that has been passe...   \n",
       "188  To see the natural world flourish, long after ...   \n",
       "189  Against Queen Nehelenia, she was a tough oppon...   \n",
       "190       \"Difficult decisions, for the greater good.\"   \n",
       "191       They are a nuisance that must be dealt with.   \n",
       "\n",
       "                                           gen_replies  \\\n",
       "0                       Lack of resources and support.   \n",
       "1    I find it amusing to watch people's reactions ...   \n",
       "2                      Honorable, fearless, dedicated.   \n",
       "3                    Cities are no place for a ranger.   \n",
       "4                   My family, they are my motivation.   \n",
       "..                                                 ...   \n",
       "187  I have a magical amulet that has been passed d...   \n",
       "188  That is difficult to answer. I live in the mom...   \n",
       "189  The battle against Queen Beryl, the sorceress,...   \n",
       "190                          Difficult, but necessary.   \n",
       "191                 They're just obstacles in my path.   \n",
       "\n",
       "                                         based_replies  \n",
       "0    The biggest challenge I face as a teacher is b...  \n",
       "1    Ah, my dear friend, your curiosity warms my he...  \n",
       "2    As a Knight Templar, I can be described as val...  \n",
       "3    No, I have never been to a city. As a creature...  \n",
       "4    As Tiger, my work and my team are the most val...  \n",
       "..                                                 ...  \n",
       "187  Ah, the question of magic and its cherished tr...  \n",
       "188  Ah, my dear adventurers, I often ponder the gr...  \n",
       "189  As a Sailor Scout, I've faced countless battle...  \n",
       "190  Indeed, as a Knight Templar, I have faced many...  \n",
       "191  Well, they do try, don't they? Always chasing ...  \n",
       "\n",
       "[192 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Response', 'gen_replies', 'based_replies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebb03843-439a-4740-8788-957d85b63ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Query</th>\n",
       "      <th>Response</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>gen_replies</th>\n",
       "      <th>based_replies</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naina Mathur</td>\n",
       "      <td>Naina Mathur is a determined and passionate te...</td>\n",
       "      <td>What is the biggest challenge you face as a te...</td>\n",
       "      <td>Ensuring every student receives the individual...</td>\n",
       "      <td>Concern</td>\n",
       "      <td>Lack of resources and support.</td>\n",
       "      <td>The biggest challenge I face as a teacher is b...</td>\n",
       "      <td>You are Naina Mathur, Naina Mathur is a determ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>Zephyr is a mischievous fairy who loves playin...</td>\n",
       "      <td>What motivates you to play pranks on people?</td>\n",
       "      <td>It's just who I am, I guess. I love seeing peo...</td>\n",
       "      <td>Playfulness</td>\n",
       "      <td>I find it amusing to watch people's reactions ...</td>\n",
       "      <td>Ah, my dear friend, your curiosity warms my he...</td>\n",
       "      <td>You are Zephyr, Zephyr is a mischievous fairy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arn, the Knight Templar</td>\n",
       "      <td>Arn is a highly skilled and honorable knight,</td>\n",
       "      <td>Can you describe yourself in three words?</td>\n",
       "      <td>\"Courageous, dedicated, honorable.\"</td>\n",
       "      <td>Pride</td>\n",
       "      <td>Honorable, fearless, dedicated.</td>\n",
       "      <td>As a Knight Templar, I can be described as val...</td>\n",
       "      <td>You are Arn, the Knight Templar, Arn is a high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arinthal</td>\n",
       "      <td>Arinthal is an elven ranger from the ancient f...</td>\n",
       "      <td>Have you ever been to a city?</td>\n",
       "      <td>Cities are noisy and overwhelming.</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Cities are no place for a ranger.</td>\n",
       "      <td>No, I have never been to a city. As a creature...</td>\n",
       "      <td>You are Arinthal, Arinthal is an elven ranger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiger</td>\n",
       "      <td>Tiger is a highly skilled and fearless spy wor...</td>\n",
       "      <td>What is the most valuable thing in your life?</td>\n",
       "      <td>My country and the people I love.</td>\n",
       "      <td>Love</td>\n",
       "      <td>My family, they are my motivation.</td>\n",
       "      <td>As Tiger, my work and my team are the most val...</td>\n",
       "      <td>You are Tiger, Tiger is a highly skilled and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Marcella Ravenwood</td>\n",
       "      <td>Marcella Ravenwood is a powerful sorceress who...</td>\n",
       "      <td>Do you have any magical artifacts that you che...</td>\n",
       "      <td>Yes, I have a magical tome that has been passe...</td>\n",
       "      <td>Sentimental</td>\n",
       "      <td>I have a magical amulet that has been passed d...</td>\n",
       "      <td>Ah, the question of magic and its cherished tr...</td>\n",
       "      <td>You are Marcella Ravenwood, Marcella Ravenwood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Lyra Dawnstrider</td>\n",
       "      <td>Lyra Dawnstrider is a high-elf ranger from the...</td>\n",
       "      <td>What is your ultimate goal in life?</td>\n",
       "      <td>To see the natural world flourish, long after ...</td>\n",
       "      <td>Peacefulness</td>\n",
       "      <td>That is difficult to answer. I live in the mom...</td>\n",
       "      <td>Ah, my dear adventurers, I often ponder the gr...</td>\n",
       "      <td>You are Lyra Dawnstrider, Lyra Dawnstrider is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Sailor Moon</td>\n",
       "      <td>Sailor Moon is the protector of the galaxy, de...</td>\n",
       "      <td>What is the most challenging battle you've fou...</td>\n",
       "      <td>Against Queen Nehelenia, she was a tough oppon...</td>\n",
       "      <td>Triumphant</td>\n",
       "      <td>The battle against Queen Beryl, the sorceress,...</td>\n",
       "      <td>As a Sailor Scout, I've faced countless battle...</td>\n",
       "      <td>You are Sailor Moon, Sailor Moon is the protec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Arn, the Knight Templar</td>\n",
       "      <td>Arn is a highly skilled and honorable knight,</td>\n",
       "      <td>Have you ever made a difficult decision?</td>\n",
       "      <td>\"Difficult decisions, for the greater good.\"</td>\n",
       "      <td>Conviction</td>\n",
       "      <td>Difficult, but necessary.</td>\n",
       "      <td>Indeed, as a Knight Templar, I have faced many...</td>\n",
       "      <td>You are Arn, the Knight Templar, Arn is a high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Light Yagami</td>\n",
       "      <td>Light Yagami is a highly intelligent high scho...</td>\n",
       "      <td>What do you think of the police?</td>\n",
       "      <td>They are a nuisance that must be dealt with.</td>\n",
       "      <td>Contemptuous</td>\n",
       "      <td>They're just obstacles in my path.</td>\n",
       "      <td>Well, they do try, don't they? Always chasing ...</td>\n",
       "      <td>You are Light Yagami, Light Yagami is a highly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  \\\n",
       "0               Naina Mathur   \n",
       "1                     Zephyr   \n",
       "2    Arn, the Knight Templar   \n",
       "3                   Arinthal   \n",
       "4                      Tiger   \n",
       "..                       ...   \n",
       "187       Marcella Ravenwood   \n",
       "188         Lyra Dawnstrider   \n",
       "189              Sailor Moon   \n",
       "190  Arn, the Knight Templar   \n",
       "191             Light Yagami   \n",
       "\n",
       "                                             Biography  \\\n",
       "0    Naina Mathur is a determined and passionate te...   \n",
       "1    Zephyr is a mischievous fairy who loves playin...   \n",
       "2        Arn is a highly skilled and honorable knight,   \n",
       "3    Arinthal is an elven ranger from the ancient f...   \n",
       "4    Tiger is a highly skilled and fearless spy wor...   \n",
       "..                                                 ...   \n",
       "187  Marcella Ravenwood is a powerful sorceress who...   \n",
       "188  Lyra Dawnstrider is a high-elf ranger from the...   \n",
       "189  Sailor Moon is the protector of the galaxy, de...   \n",
       "190      Arn is a highly skilled and honorable knight,   \n",
       "191  Light Yagami is a highly intelligent high scho...   \n",
       "\n",
       "                                                 Query  \\\n",
       "0    What is the biggest challenge you face as a te...   \n",
       "1         What motivates you to play pranks on people?   \n",
       "2            Can you describe yourself in three words?   \n",
       "3                        Have you ever been to a city?   \n",
       "4        What is the most valuable thing in your life?   \n",
       "..                                                 ...   \n",
       "187  Do you have any magical artifacts that you che...   \n",
       "188                What is your ultimate goal in life?   \n",
       "189  What is the most challenging battle you've fou...   \n",
       "190           Have you ever made a difficult decision?   \n",
       "191                   What do you think of the police?   \n",
       "\n",
       "                                              Response       Emotion  \\\n",
       "0    Ensuring every student receives the individual...       Concern   \n",
       "1    It's just who I am, I guess. I love seeing peo...   Playfulness   \n",
       "2                  \"Courageous, dedicated, honorable.\"         Pride   \n",
       "3                   Cities are noisy and overwhelming.       Disgust   \n",
       "4                    My country and the people I love.          Love   \n",
       "..                                                 ...           ...   \n",
       "187  Yes, I have a magical tome that has been passe...   Sentimental   \n",
       "188  To see the natural world flourish, long after ...  Peacefulness   \n",
       "189  Against Queen Nehelenia, she was a tough oppon...    Triumphant   \n",
       "190       \"Difficult decisions, for the greater good.\"    Conviction   \n",
       "191       They are a nuisance that must be dealt with.  Contemptuous   \n",
       "\n",
       "                                           gen_replies  \\\n",
       "0                       Lack of resources and support.   \n",
       "1    I find it amusing to watch people's reactions ...   \n",
       "2                      Honorable, fearless, dedicated.   \n",
       "3                    Cities are no place for a ranger.   \n",
       "4                   My family, they are my motivation.   \n",
       "..                                                 ...   \n",
       "187  I have a magical amulet that has been passed d...   \n",
       "188  That is difficult to answer. I live in the mom...   \n",
       "189  The battle against Queen Beryl, the sorceress,...   \n",
       "190                          Difficult, but necessary.   \n",
       "191                 They're just obstacles in my path.   \n",
       "\n",
       "                                         based_replies  \\\n",
       "0    The biggest challenge I face as a teacher is b...   \n",
       "1    Ah, my dear friend, your curiosity warms my he...   \n",
       "2    As a Knight Templar, I can be described as val...   \n",
       "3    No, I have never been to a city. As a creature...   \n",
       "4    As Tiger, my work and my team are the most val...   \n",
       "..                                                 ...   \n",
       "187  Ah, the question of magic and its cherished tr...   \n",
       "188  Ah, my dear adventurers, I often ponder the gr...   \n",
       "189  As a Sailor Scout, I've faced countless battle...   \n",
       "190  Indeed, as a Knight Templar, I have faced many...   \n",
       "191  Well, they do try, don't they? Always chasing ...   \n",
       "\n",
       "                                                prompt  \n",
       "0    You are Naina Mathur, Naina Mathur is a determ...  \n",
       "1    You are Zephyr, Zephyr is a mischievous fairy ...  \n",
       "2    You are Arn, the Knight Templar, Arn is a high...  \n",
       "3    You are Arinthal, Arinthal is an elven ranger ...  \n",
       "4    You are Tiger, Tiger is a highly skilled and f...  \n",
       "..                                                 ...  \n",
       "187  You are Marcella Ravenwood, Marcella Ravenwood...  \n",
       "188  You are Lyra Dawnstrider, Lyra Dawnstrider is ...  \n",
       "189  You are Sailor Moon, Sailor Moon is the protec...  \n",
       "190  You are Arn, the Knight Templar, Arn is a high...  \n",
       "191  You are Light Yagami, Light Yagami is a highly...  \n",
       "\n",
       "[192 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb939a-6506-4e41-8570-22bbd368dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(example):\n",
    "    system = f\"You are {example['Name']}, {example['Biography']} Respond in character to the query \\\"{example['Query']}\\\" with emotion: {example['Emotion']}.\"\n",
    "    return system\n",
    "    \n",
    "prompts_lst = []\n",
    "for idx, row in df.iterrows():\n",
    "    prompt = get_prompt(row)\n",
    "    prompts_lst.append(prompt)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c98da30f-0cd5-4dbf-afca-64ccf52fb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = prompts_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f05eb957-a405-40bb-9eaf-2b2ded2b8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_metrics = df.apply(lambda row:compute_all_metrics([row['gen_replies']], [row['Response']]), axis=1)\n",
    "df = pd.concat([df, pd.json_normalize(gen_metrics).add_prefix('ft_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3b0e7-01d3-4eaf-a03f-0c4b8f3e5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_metrics = df.apply(lambda row:compute_all_metrics([row['based_replies']], [row['Response']]), axis=1)\n",
    "df = pd.concat([df, pd.json_normalize(gen_metrics).add_prefix('based_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b3f3707-ecf8-4897-ad68-dff72afca464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'based_bleu': 0.008414975823281785,\n",
       " 'based_rouge1': 0.16070326151895276,\n",
       " 'based_rouge2': 0.03276037648254885,\n",
       " 'based_rougeL': 0.12214035387414375,\n",
       " 'based_bertscore_f1': 0.8552154352267584}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(regex='based_(1|b|ro)').mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3292a5e2-99b4-4357-bf90-7d5716e52649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ft_bleu': 0.03798126173187139,\n",
       " 'ft_rouge1': 0.28215202473074,\n",
       " 'ft_rouge2': 0.110212849354509,\n",
       " 'ft_rougeL': 0.2502723021685273,\n",
       " 'ft_bertscore_f1': 0.8908860826243957}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(regex='ft_*').mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbb150bb-5e33-488e-9609-8ad6d6b84fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('final_res_test_max_token150.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be7118-dcda-4cd3-bfe2-078f9c126d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
